{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MRP-fAQedMTd"
   },
   "source": [
    "<h2> 3.6 Featurizing text data with tfidf weighted word-vectors </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3IbomL8dMTi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 182010,
     "status": "ok",
     "timestamp": 1565703039911,
     "user": {
      "displayName": "Mukesh Mishra",
      "photoUrl": "https://lh4.googleusercontent.com/-sz7NIbVC0ho/AAAAAAAAAAI/AAAAAAAADcQ/UgdGcXvpJOI/s64/photo.jpg",
      "userId": "15923203954827925545"
     },
     "user_tz": -330
    },
    "id": "td2hQVzhQxD9",
    "outputId": "5b7659c3-844d-4872-8fae-2b8c3586aff2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 993kB 45.3MB/s eta 0:00:01\n",
      "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "\n",
    "id1='1gTfCTD3fz-3NJnfYLm59nZFN3WC3fzfD'\n",
    "downloaded1 = drive.CreateFile({'id': id1})\n",
    "downloaded1.GetContentFile('df_fe_without_preprocessing_train.csv')\n",
    "\n",
    "id2='1JncN1Fyt-ND_yZXOzqEfcRsYMTKqtu7Q'\n",
    "downloaded1 = drive.CreateFile({'id': id2})\n",
    "downloaded1.GetContentFile('nlp_features_train.csv')\n",
    "\n",
    "  \n",
    "id3='10QDGTSI5PEV9e7CTpfzsXRpUwRIsJA-J'\n",
    "downloaded1 = drive.CreateFile({'id': id3})\n",
    "downloaded1.GetContentFile('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5XNgVyLdMT7"
   },
   "outputs": [],
   "source": [
    "# avoid decoding problems\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "# merge texts\n",
    "df_train,df_test=train_test_split(df,test_size=0.2)\n",
    "\n",
    "# encode questions to unicode\n",
    "# https://stackoverflow.com/a/6812069\n",
    "# ----------------- python 2 ---------------------\n",
    "# df['question1'] = df['question1'].apply(lambda x: unicode(str(x),\"utf-8\"))\n",
    "# df['question2'] = df['question2'].apply(lambda x: unicode(str(x),\"utf-8\"))\n",
    "# ----------------- python 3 ---------------------\n",
    "df_train['question1'] = df_train['question1'].apply(lambda x: str(x))\n",
    "df_train['question2'] = df_train['question2'].apply(lambda x: str(x))\n",
    "\n",
    "df_test['question1'] = df_test['question1'].apply(lambda x: str(x))\n",
    "df_test['question2'] = df_test['question2'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 184057,
     "status": "ok",
     "timestamp": 1565703041985,
     "user": {
      "displayName": "Mukesh Mishra",
      "photoUrl": "https://lh4.googleusercontent.com/-sz7NIbVC0ho/AAAAAAAAAAI/AAAAAAAADcQ/UgdGcXvpJOI/s64/photo.jpg",
      "userId": "15923203954827925545"
     },
     "user_tz": -330
    },
    "id": "HbiMFpgRdMUJ",
    "outputId": "5b2e4bda-049f-4940-e741-844596a90eb3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  ...                                          question2 is_duplicate\n",
       "0   0     1  ...  What is the step by step guide to invest in sh...            0\n",
       "1   1     3  ...  What would happen if the Indian government sto...            0\n",
       "\n",
       "[2 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RU3HqJXwdMUj"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# merge texts\n",
    "questions = list(df_train['question1']) + list(df_train['question2'])\n",
    "\n",
    "tfidf = TfidfVectorizer(lowercase=False, )\n",
    "tfidf.fit_transform(questions)\n",
    "\n",
    "# dict key:word and value:tf-idf score\n",
    "word2tfidf = dict(zip(tfidf.get_feature_names(), tfidf.idf_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2JKI2yT4dMUv"
   },
   "source": [
    "- After we find TF-IDF scores, we convert each question to a weighted average of word2vec vectors by these scores.\n",
    "- here we use a pre-trained GLOVE model which comes free with \"Spacy\".  https://spacy.io/usage/vectors-similarity\n",
    "- It is trained on Wikipedia and therefore, it is stronger in terms of word semantics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2588494,
     "status": "ok",
     "timestamp": 1565705736851,
     "user": {
      "displayName": "Mukesh Mishra",
      "photoUrl": "https://lh4.googleusercontent.com/-sz7NIbVC0ho/AAAAAAAAAAI/AAAAAAAADcQ/UgdGcXvpJOI/s64/photo.jpg",
      "userId": "15923203954827925545"
     },
     "user_tz": -330
    },
    "id": "PFS6m8z5dMUz",
    "outputId": "7ddc9b53-567c-4558-8940-52d9d1fbf709"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323432/323432 [43:06<00:00, 125.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# en_vectors_web_lg, which includes over 1 million unique vectors.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "vecs1 = []\n",
    "# https://github.com/noamraph/tqdm\n",
    "# tqdm is used to print the progress bar\n",
    "for qu1 in tqdm(list(df_train['question1'])):\n",
    "    doc1 = nlp(qu1) \n",
    "    # 96 is the number of dimensions of vectors \n",
    "    mean_vec1 = np.zeros([len(doc1), len(doc1[0].vector)])\n",
    "    for word1 in doc1:\n",
    "        # word2vec\n",
    "        vec1 = word1.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            tfidf = word2tfidf[str(word1)] * (qu1.count(str(word1))/len(qu1.split()))\n",
    "        except:\n",
    "            tfidf = 0\n",
    "        # compute final vec\n",
    "        mean_vec1 += vec1 * tfidf\n",
    "    mean_vec1 = mean_vec1.mean(axis=0)\n",
    "    vecs1.append(mean_vec1)\n",
    "df_train['q1_feats_m'] = list(vecs1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JX4UmbS6LjfC"
   },
   "outputs": [],
   "source": [
    "df_train.to_csv('mid1.csv')\n",
    "df_test.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2466867,
     "status": "ok",
     "timestamp": 1565713711891,
     "user": {
      "displayName": "Mukesh Mishra",
      "photoUrl": "https://lh4.googleusercontent.com/-sz7NIbVC0ho/AAAAAAAAAAI/AAAAAAAADcQ/UgdGcXvpJOI/s64/photo.jpg",
      "userId": "15923203954827925545"
     },
     "user_tz": -330
    },
    "id": "62GEF-RbdMVB",
    "outputId": "20eee552-d706-48fb-c553-fc0c06812285"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323432/323432 [41:04<00:00, 131.24it/s]\n"
     ]
    }
   ],
   "source": [
    "vecs2 = []\n",
    "from tqdm import tqdm\n",
    "for qu2 in tqdm(list(df_train['question2'])):\n",
    "    doc2 = nlp(qu2) \n",
    "    mean_vec2 = np.zeros([len(doc2), len(doc2[0].vector)])\n",
    "    for word2 in doc2:\n",
    "        # word2vec\n",
    "        vec2 = word2.vector\n",
    "        # fetch df score\n",
    "\n",
    "        try:\n",
    "            \n",
    "            tfidf = word2tfidf[str(word2)] * (qu2.count(str(word2))/len(qu2.split()))\n",
    "        except:\n",
    "            #print word\n",
    "            tfidf = 0\n",
    "        # compute final vec\n",
    "        \n",
    "        #print(tfidf)\n",
    "        mean_vec2 += vec2 * tfidf\n",
    "    mean_vec2 = mean_vec2.mean(axis=0)\n",
    "    \n",
    "    vecs2.append(mean_vec2)\n",
    "df_train['q2_feats_m'] = list(vecs2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1253806,
     "status": "ok",
     "timestamp": 1565716262348,
     "user": {
      "displayName": "Mukesh Mishra",
      "photoUrl": "https://lh4.googleusercontent.com/-sz7NIbVC0ho/AAAAAAAAAAI/AAAAAAAADcQ/UgdGcXvpJOI/s64/photo.jpg",
      "userId": "15923203954827925545"
     },
     "user_tz": -330
    },
    "id": "mS7NrBRKR5NN",
    "outputId": "9ef5687c-91a9-45b9-db37-08d8922a418d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80858/80858 [10:44<00:00, 125.52it/s]\n",
      "100%|██████████| 80858/80858 [10:07<00:00, 133.04it/s]\n"
     ]
    }
   ],
   "source": [
    "#Test Features Questions1 and Questions2\n",
    "# en_vectors_web_lg, which includes over 1 million unique vectors.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "vecs1 = []\n",
    "# https://github.com/noamraph/tqdm\n",
    "# tqdm is used to print the progress bar\n",
    "for qu1 in tqdm(list(df_test['question1'])):\n",
    "    doc1 = nlp(qu1) \n",
    "    # 384 is the number of dimensions of vectors \n",
    "    mean_vec1 = np.zeros([len(doc1), len(doc1[0].vector)])\n",
    "    for word1 in doc1:\n",
    "        # word2vec\n",
    "        vec1 = word1.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            tfidf = word2tfidf[str(word1)] * (qu1.count(str(word1))/len(qu1.split()))\n",
    "        except:\n",
    "            tfidf = 0\n",
    "        # compute final vec\n",
    "        mean_vec1 += vec1 * tfidf\n",
    "    mean_vec1 = mean_vec1.mean(axis=0)\n",
    "    vecs1.append(mean_vec1)\n",
    "df_test['q1_feats_m'] = list(vecs1)\n",
    "\n",
    "########################################\n",
    "\n",
    "vecs2 = []\n",
    "for qu2 in tqdm(list(df_test['question2'])):\n",
    "    doc2 = nlp(qu2) \n",
    "    mean_vec2 = np.zeros([len(doc2), len(doc2[0].vector)])\n",
    "    for word2 in doc2:\n",
    "        # word2vec\n",
    "        vec2 = word2.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            tfidf = word2tfidf[str(word2)] * (qu2.count(str(word2))/len(qu2.split()))\n",
    "        except:\n",
    "            #print word\n",
    "            tfidf = 0\n",
    "        # compute final vec\n",
    "        mean_vec2 += vec2 * tfidf\n",
    "    mean_vec2 = mean_vec2.mean(axis=0)\n",
    "    vecs2.append(mean_vec2)\n",
    "df_test['q2_feats_m'] = list(vecs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2575,
     "status": "ok",
     "timestamp": 1565716565307,
     "user": {
      "displayName": "Mukesh Mishra",
      "photoUrl": "https://lh4.googleusercontent.com/-sz7NIbVC0ho/AAAAAAAAAAI/AAAAAAAADcQ/UgdGcXvpJOI/s64/photo.jpg",
      "userId": "15923203954827925545"
     },
     "user_tz": -330
    },
    "id": "etcoGm662sze",
    "outputId": "d83550d0-ede8-4529-e55e-9f9c13d37e65"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_feats_m</th>\n",
       "      <th>q2_feats_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287851</th>\n",
       "      <td>287851</td>\n",
       "      <td>408683</td>\n",
       "      <td>408684</td>\n",
       "      <td>What are some examples of terrestrial animals?</td>\n",
       "      <td>What are terrestrial animals? What are example...</td>\n",
       "      <td>1</td>\n",
       "      <td>[9.50959499180317, -2.984976351261139, -11.809...</td>\n",
       "      <td>[4.78945130109787, -5.7303591668605804, -9.730...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172952</th>\n",
       "      <td>172952</td>\n",
       "      <td>266924</td>\n",
       "      <td>266925</td>\n",
       "      <td>Why is ASEAN one of the most peaceful and pros...</td>\n",
       "      <td>Why and how did Lebanon become the most peacef...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.6344003081321716, -1.813245631987229, -12.8...</td>\n",
       "      <td>[-7.4249771372415125, -6.347789332270622, -11....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  ...                                         q2_feats_m\n",
       "287851  287851  ...  [4.78945130109787, -5.7303591668605804, -9.730...\n",
       "172952  172952  ...  [-7.4249771372415125, -6.347789332270622, -11....\n",
       "\n",
       "[2 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a38GBlGWdMVQ"
   },
   "outputs": [],
   "source": [
    "#prepro_features_train.csv (Simple Preprocessing Feartures)\n",
    "#nlp_features_train.csv (NLP Features)\n",
    "if os.path.isfile('nlp_features_train.csv'):\n",
    "    dfnlp = pd.read_csv(\"nlp_features_train.csv\",encoding='latin-1')\n",
    "else:\n",
    "    print(\"download nlp_features_train.csv from drive or run previous notebook\")\n",
    "\n",
    "if os.path.isfile('df_fe_without_preprocessing_train.csv'):\n",
    "    dfppro = pd.read_csv(\"df_fe_without_preprocessing_train.csv\",encoding='latin-1')\n",
    "else:\n",
    "    print(\"download df_fe_without_preprocessing_train.csv from drive or run previous notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "apdRa1kndMVb"
   },
   "outputs": [],
   "source": [
    "df1 = dfnlp.drop(['qid1','qid2','question1','question2'],axis=1)\n",
    "df2 = dfppro.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n",
    "\n",
    "\n",
    "df3_train = df_train.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n",
    "df3_test = df_test.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n",
    "\n",
    "df3_q1_train = pd.DataFrame(df3_train.q1_feats_m.values.tolist(), index= df3_train.index)\n",
    "df3_q2_train = pd.DataFrame(df3_train.q2_feats_m.values.tolist(), index= df3_train.index)\n",
    "\n",
    "df3_q1_test = pd.DataFrame(df3_test.q1_feats_m.values.tolist(), index= df3_test.index)\n",
    "df3_q2_test = pd.DataFrame(df3_test.q2_feats_m.values.tolist(), index= df3_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "xzWAqGegdMVp",
    "outputId": "4d753441-c0ee-4e43-a0dd-44dff5853c61"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.916659</td>\n",
       "      <td>0.785709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>100</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "      <td>0.982759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.699993</td>\n",
       "      <td>0.466664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>86</td>\n",
       "      <td>63</td>\n",
       "      <td>66</td>\n",
       "      <td>75</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.285712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>0.039216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.199998</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>67</td>\n",
       "      <td>47</td>\n",
       "      <td>46</td>\n",
       "      <td>56</td>\n",
       "      <td>0.175000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  is_duplicate  ...  fuzz_partial_ratio  longest_substr_ratio\n",
       "0   0             0  ...                 100              0.982759\n",
       "1   1             0  ...                  75              0.596154\n",
       "2   2             0  ...                  54              0.166667\n",
       "3   3             0  ...                  40              0.039216\n",
       "4   4             0  ...                  56              0.175000\n",
       "\n",
       "[5 rows x 17 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe of nlp features\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "N4DQnDtndMV4",
    "outputId": "0927903b-48f3-4118-94d4-48aec4912b06"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>freq_qid1</th>\n",
       "      <th>freq_qid2</th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>q1_n_words</th>\n",
       "      <th>q2_n_words</th>\n",
       "      <th>word_Common</th>\n",
       "      <th>word_Total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>freq_q1+q2</th>\n",
       "      <th>freq_q1-q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  freq_qid1  freq_qid2  ...  word_share  freq_q1+q2  freq_q1-q2\n",
       "0   0          1          1  ...    0.434783           2           0\n",
       "1   1          4          1  ...    0.200000           5           3\n",
       "2   2          1          1  ...    0.166667           2           0\n",
       "3   3          1          1  ...    0.000000           2           0\n",
       "4   4          3          1  ...    0.100000           4           2\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data before preprocessing \n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13667,
     "status": "ok",
     "timestamp": 1565716606332,
     "user": {
      "displayName": "Mukesh Mishra",
      "photoUrl": "https://lh4.googleusercontent.com/-sz7NIbVC0ho/AAAAAAAAAAI/AAAAAAAADcQ/UgdGcXvpJOI/s64/photo.jpg",
      "userId": "15923203954827925545"
     },
     "user_tz": -330
    },
    "id": "_1YIPtTwdMWC",
    "outputId": "ee7ff3dc-bc81-4c4b-eb8d-bda7668055b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287851</th>\n",
       "      <td>9.509595</td>\n",
       "      <td>-2.984976</td>\n",
       "      <td>-11.809498</td>\n",
       "      <td>-9.398076</td>\n",
       "      <td>3.067511</td>\n",
       "      <td>8.801890</td>\n",
       "      <td>18.589524</td>\n",
       "      <td>13.412171</td>\n",
       "      <td>-8.947324</td>\n",
       "      <td>3.094738</td>\n",
       "      <td>1.691513</td>\n",
       "      <td>8.095941</td>\n",
       "      <td>-6.303056</td>\n",
       "      <td>-0.427843</td>\n",
       "      <td>-7.003376</td>\n",
       "      <td>-0.748968</td>\n",
       "      <td>4.154996</td>\n",
       "      <td>-2.291023</td>\n",
       "      <td>8.080150</td>\n",
       "      <td>8.278644</td>\n",
       "      <td>-6.462129</td>\n",
       "      <td>-0.737898</td>\n",
       "      <td>-0.235452</td>\n",
       "      <td>4.537895</td>\n",
       "      <td>4.017996</td>\n",
       "      <td>7.173647</td>\n",
       "      <td>1.704798</td>\n",
       "      <td>1.237732</td>\n",
       "      <td>10.924204</td>\n",
       "      <td>5.328782</td>\n",
       "      <td>2.646659</td>\n",
       "      <td>-6.434639</td>\n",
       "      <td>-7.008202</td>\n",
       "      <td>-6.083318</td>\n",
       "      <td>6.618583</td>\n",
       "      <td>2.543236</td>\n",
       "      <td>-5.672268</td>\n",
       "      <td>10.457816</td>\n",
       "      <td>-8.264491</td>\n",
       "      <td>18.614475</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.419065</td>\n",
       "      <td>1.236458</td>\n",
       "      <td>-5.794618</td>\n",
       "      <td>-1.939053</td>\n",
       "      <td>-4.704448</td>\n",
       "      <td>-2.556173</td>\n",
       "      <td>15.138295</td>\n",
       "      <td>-7.257904</td>\n",
       "      <td>-4.743637</td>\n",
       "      <td>9.749738</td>\n",
       "      <td>-1.817478</td>\n",
       "      <td>3.658660</td>\n",
       "      <td>-7.542569</td>\n",
       "      <td>-3.279955</td>\n",
       "      <td>-3.166110</td>\n",
       "      <td>-0.905803</td>\n",
       "      <td>5.192864</td>\n",
       "      <td>-0.364392</td>\n",
       "      <td>7.728776</td>\n",
       "      <td>1.199033</td>\n",
       "      <td>12.618125</td>\n",
       "      <td>-9.968715</td>\n",
       "      <td>-6.569936</td>\n",
       "      <td>-4.077975</td>\n",
       "      <td>-10.841807</td>\n",
       "      <td>-14.701773</td>\n",
       "      <td>-5.615776</td>\n",
       "      <td>14.994381</td>\n",
       "      <td>0.695577</td>\n",
       "      <td>-4.842362</td>\n",
       "      <td>3.442499</td>\n",
       "      <td>1.640088</td>\n",
       "      <td>6.817366</td>\n",
       "      <td>3.112806</td>\n",
       "      <td>-1.793013</td>\n",
       "      <td>3.135360</td>\n",
       "      <td>-3.560157</td>\n",
       "      <td>1.866096</td>\n",
       "      <td>-4.823692</td>\n",
       "      <td>-0.425846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172952</th>\n",
       "      <td>0.634400</td>\n",
       "      <td>-1.813246</td>\n",
       "      <td>-12.816122</td>\n",
       "      <td>-12.080643</td>\n",
       "      <td>5.457196</td>\n",
       "      <td>6.322567</td>\n",
       "      <td>15.836552</td>\n",
       "      <td>13.633682</td>\n",
       "      <td>0.312183</td>\n",
       "      <td>8.396769</td>\n",
       "      <td>0.150165</td>\n",
       "      <td>7.360641</td>\n",
       "      <td>-5.962791</td>\n",
       "      <td>-7.630841</td>\n",
       "      <td>-5.020401</td>\n",
       "      <td>3.522857</td>\n",
       "      <td>2.372590</td>\n",
       "      <td>7.632984</td>\n",
       "      <td>3.762090</td>\n",
       "      <td>8.595857</td>\n",
       "      <td>-7.852826</td>\n",
       "      <td>-9.295640</td>\n",
       "      <td>4.023685</td>\n",
       "      <td>13.181084</td>\n",
       "      <td>5.077215</td>\n",
       "      <td>7.039378</td>\n",
       "      <td>7.549188</td>\n",
       "      <td>-0.501529</td>\n",
       "      <td>4.046289</td>\n",
       "      <td>17.695318</td>\n",
       "      <td>7.906723</td>\n",
       "      <td>-6.016496</td>\n",
       "      <td>-8.967220</td>\n",
       "      <td>-2.282251</td>\n",
       "      <td>7.592375</td>\n",
       "      <td>6.390906</td>\n",
       "      <td>-1.614485</td>\n",
       "      <td>5.990179</td>\n",
       "      <td>-10.741943</td>\n",
       "      <td>10.547681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.509952</td>\n",
       "      <td>6.118096</td>\n",
       "      <td>-11.951702</td>\n",
       "      <td>-3.893855</td>\n",
       "      <td>-1.671958</td>\n",
       "      <td>-4.216384</td>\n",
       "      <td>1.241491</td>\n",
       "      <td>-2.646215</td>\n",
       "      <td>-3.549613</td>\n",
       "      <td>6.363665</td>\n",
       "      <td>-1.073801</td>\n",
       "      <td>-8.755880</td>\n",
       "      <td>-10.410566</td>\n",
       "      <td>-10.266473</td>\n",
       "      <td>2.105469</td>\n",
       "      <td>8.306117</td>\n",
       "      <td>3.856037</td>\n",
       "      <td>3.997876</td>\n",
       "      <td>3.283546</td>\n",
       "      <td>-2.170684</td>\n",
       "      <td>12.741116</td>\n",
       "      <td>-12.991741</td>\n",
       "      <td>-6.143995</td>\n",
       "      <td>-8.938692</td>\n",
       "      <td>-8.198422</td>\n",
       "      <td>-6.042458</td>\n",
       "      <td>-4.802310</td>\n",
       "      <td>8.049190</td>\n",
       "      <td>-5.368274</td>\n",
       "      <td>6.490154</td>\n",
       "      <td>9.402603</td>\n",
       "      <td>2.374286</td>\n",
       "      <td>0.734876</td>\n",
       "      <td>2.210260</td>\n",
       "      <td>3.313199</td>\n",
       "      <td>3.587876</td>\n",
       "      <td>-9.266031</td>\n",
       "      <td>3.471059</td>\n",
       "      <td>2.444621</td>\n",
       "      <td>1.979798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247768</th>\n",
       "      <td>4.431505</td>\n",
       "      <td>-4.361650</td>\n",
       "      <td>-14.430818</td>\n",
       "      <td>-18.104730</td>\n",
       "      <td>-2.806155</td>\n",
       "      <td>6.768903</td>\n",
       "      <td>9.910724</td>\n",
       "      <td>4.264563</td>\n",
       "      <td>-0.473978</td>\n",
       "      <td>10.360899</td>\n",
       "      <td>-4.802288</td>\n",
       "      <td>-1.079249</td>\n",
       "      <td>-19.055429</td>\n",
       "      <td>-3.026365</td>\n",
       "      <td>-3.590284</td>\n",
       "      <td>-2.060192</td>\n",
       "      <td>-1.798055</td>\n",
       "      <td>6.740497</td>\n",
       "      <td>4.999477</td>\n",
       "      <td>8.722835</td>\n",
       "      <td>-3.349558</td>\n",
       "      <td>-5.820761</td>\n",
       "      <td>8.355772</td>\n",
       "      <td>6.227257</td>\n",
       "      <td>8.459014</td>\n",
       "      <td>2.607435</td>\n",
       "      <td>8.793812</td>\n",
       "      <td>-2.773101</td>\n",
       "      <td>-0.665938</td>\n",
       "      <td>15.091018</td>\n",
       "      <td>12.850567</td>\n",
       "      <td>-9.745835</td>\n",
       "      <td>-1.240837</td>\n",
       "      <td>-0.605949</td>\n",
       "      <td>7.560911</td>\n",
       "      <td>-1.937670</td>\n",
       "      <td>2.289374</td>\n",
       "      <td>9.414200</td>\n",
       "      <td>-3.008853</td>\n",
       "      <td>1.216820</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.822593</td>\n",
       "      <td>-3.240056</td>\n",
       "      <td>-6.264749</td>\n",
       "      <td>9.042799</td>\n",
       "      <td>-4.246354</td>\n",
       "      <td>-4.030239</td>\n",
       "      <td>15.877108</td>\n",
       "      <td>-2.235856</td>\n",
       "      <td>-4.093766</td>\n",
       "      <td>9.954416</td>\n",
       "      <td>-2.260144</td>\n",
       "      <td>10.709959</td>\n",
       "      <td>-3.060452</td>\n",
       "      <td>9.768427</td>\n",
       "      <td>4.333365</td>\n",
       "      <td>-5.513066</td>\n",
       "      <td>13.107864</td>\n",
       "      <td>8.112344</td>\n",
       "      <td>13.303394</td>\n",
       "      <td>8.201615</td>\n",
       "      <td>0.741760</td>\n",
       "      <td>-2.043699</td>\n",
       "      <td>-10.131824</td>\n",
       "      <td>-2.633367</td>\n",
       "      <td>-1.452103</td>\n",
       "      <td>-12.734809</td>\n",
       "      <td>-13.799173</td>\n",
       "      <td>1.847137</td>\n",
       "      <td>0.229086</td>\n",
       "      <td>-5.043510</td>\n",
       "      <td>0.072122</td>\n",
       "      <td>-14.750861</td>\n",
       "      <td>6.186821</td>\n",
       "      <td>2.483959</td>\n",
       "      <td>-2.532530</td>\n",
       "      <td>2.819104</td>\n",
       "      <td>-2.395037</td>\n",
       "      <td>-0.371811</td>\n",
       "      <td>3.454752</td>\n",
       "      <td>3.053820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97009</th>\n",
       "      <td>8.108846</td>\n",
       "      <td>-5.319327</td>\n",
       "      <td>-6.192122</td>\n",
       "      <td>-12.733797</td>\n",
       "      <td>-1.011927</td>\n",
       "      <td>4.555990</td>\n",
       "      <td>10.343346</td>\n",
       "      <td>8.802996</td>\n",
       "      <td>-1.492674</td>\n",
       "      <td>6.124089</td>\n",
       "      <td>-2.084184</td>\n",
       "      <td>3.179069</td>\n",
       "      <td>-8.062579</td>\n",
       "      <td>-4.078246</td>\n",
       "      <td>-0.651208</td>\n",
       "      <td>-0.236969</td>\n",
       "      <td>4.904613</td>\n",
       "      <td>7.411832</td>\n",
       "      <td>5.864543</td>\n",
       "      <td>13.814109</td>\n",
       "      <td>-5.158693</td>\n",
       "      <td>-2.385786</td>\n",
       "      <td>3.346305</td>\n",
       "      <td>5.559901</td>\n",
       "      <td>-0.018484</td>\n",
       "      <td>6.021548</td>\n",
       "      <td>4.847834</td>\n",
       "      <td>0.826688</td>\n",
       "      <td>4.814593</td>\n",
       "      <td>8.900593</td>\n",
       "      <td>5.123895</td>\n",
       "      <td>0.077174</td>\n",
       "      <td>-2.587443</td>\n",
       "      <td>-1.389524</td>\n",
       "      <td>7.737603</td>\n",
       "      <td>2.125724</td>\n",
       "      <td>-3.245216</td>\n",
       "      <td>3.797454</td>\n",
       "      <td>1.114827</td>\n",
       "      <td>1.629650</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.875933</td>\n",
       "      <td>4.878070</td>\n",
       "      <td>-6.997631</td>\n",
       "      <td>-2.860798</td>\n",
       "      <td>-0.978205</td>\n",
       "      <td>-0.364062</td>\n",
       "      <td>4.940702</td>\n",
       "      <td>-0.610198</td>\n",
       "      <td>-1.695569</td>\n",
       "      <td>7.536193</td>\n",
       "      <td>2.099060</td>\n",
       "      <td>4.564160</td>\n",
       "      <td>-5.394021</td>\n",
       "      <td>-2.568257</td>\n",
       "      <td>-2.209078</td>\n",
       "      <td>3.138192</td>\n",
       "      <td>0.509038</td>\n",
       "      <td>2.391164</td>\n",
       "      <td>2.291351</td>\n",
       "      <td>-1.185645</td>\n",
       "      <td>1.614205</td>\n",
       "      <td>-1.758273</td>\n",
       "      <td>-0.517461</td>\n",
       "      <td>1.757455</td>\n",
       "      <td>-5.846789</td>\n",
       "      <td>-7.959715</td>\n",
       "      <td>-10.782722</td>\n",
       "      <td>0.479260</td>\n",
       "      <td>-0.932473</td>\n",
       "      <td>-1.343219</td>\n",
       "      <td>2.279865</td>\n",
       "      <td>-0.225354</td>\n",
       "      <td>-4.746208</td>\n",
       "      <td>4.460910</td>\n",
       "      <td>0.462583</td>\n",
       "      <td>0.581240</td>\n",
       "      <td>-1.711343</td>\n",
       "      <td>1.485384</td>\n",
       "      <td>0.710626</td>\n",
       "      <td>-2.989335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223297</th>\n",
       "      <td>3.949012</td>\n",
       "      <td>-6.848152</td>\n",
       "      <td>-4.856686</td>\n",
       "      <td>-11.317435</td>\n",
       "      <td>-9.334562</td>\n",
       "      <td>1.511885</td>\n",
       "      <td>7.551820</td>\n",
       "      <td>10.383319</td>\n",
       "      <td>0.304397</td>\n",
       "      <td>9.664529</td>\n",
       "      <td>-6.060358</td>\n",
       "      <td>3.826666</td>\n",
       "      <td>-12.001611</td>\n",
       "      <td>-3.521086</td>\n",
       "      <td>2.266071</td>\n",
       "      <td>-2.369269</td>\n",
       "      <td>-1.272218</td>\n",
       "      <td>8.547030</td>\n",
       "      <td>13.582911</td>\n",
       "      <td>9.554670</td>\n",
       "      <td>-11.676729</td>\n",
       "      <td>-9.466930</td>\n",
       "      <td>11.451459</td>\n",
       "      <td>15.707175</td>\n",
       "      <td>-1.336251</td>\n",
       "      <td>1.359192</td>\n",
       "      <td>8.459381</td>\n",
       "      <td>-3.768732</td>\n",
       "      <td>-2.797023</td>\n",
       "      <td>10.526479</td>\n",
       "      <td>1.379260</td>\n",
       "      <td>-2.551673</td>\n",
       "      <td>-9.958905</td>\n",
       "      <td>-3.325168</td>\n",
       "      <td>2.606976</td>\n",
       "      <td>5.285274</td>\n",
       "      <td>4.382398</td>\n",
       "      <td>6.705949</td>\n",
       "      <td>-3.569291</td>\n",
       "      <td>2.256525</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.333005</td>\n",
       "      <td>-0.860082</td>\n",
       "      <td>-8.353470</td>\n",
       "      <td>3.883584</td>\n",
       "      <td>-1.972722</td>\n",
       "      <td>-5.209264</td>\n",
       "      <td>-1.742294</td>\n",
       "      <td>1.514132</td>\n",
       "      <td>-9.639716</td>\n",
       "      <td>7.633890</td>\n",
       "      <td>5.878526</td>\n",
       "      <td>0.721881</td>\n",
       "      <td>-8.058714</td>\n",
       "      <td>4.210082</td>\n",
       "      <td>-0.268413</td>\n",
       "      <td>-5.413268</td>\n",
       "      <td>1.458112</td>\n",
       "      <td>11.203975</td>\n",
       "      <td>4.849625</td>\n",
       "      <td>11.447165</td>\n",
       "      <td>-1.641866</td>\n",
       "      <td>-0.832450</td>\n",
       "      <td>1.123999</td>\n",
       "      <td>-5.456777</td>\n",
       "      <td>-4.471026</td>\n",
       "      <td>-0.007558</td>\n",
       "      <td>-10.340010</td>\n",
       "      <td>5.378044</td>\n",
       "      <td>0.322060</td>\n",
       "      <td>2.870553</td>\n",
       "      <td>10.669868</td>\n",
       "      <td>-7.886717</td>\n",
       "      <td>0.833996</td>\n",
       "      <td>5.668864</td>\n",
       "      <td>5.640937</td>\n",
       "      <td>1.747392</td>\n",
       "      <td>-5.997808</td>\n",
       "      <td>4.887293</td>\n",
       "      <td>-3.452863</td>\n",
       "      <td>9.012326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1          2   ...        93        94        95\n",
       "287851  9.509595 -2.984976 -11.809498  ...  1.866096 -4.823692 -0.425846\n",
       "172952  0.634400 -1.813246 -12.816122  ...  3.471059  2.444621  1.979798\n",
       "247768  4.431505 -4.361650 -14.430818  ... -0.371811  3.454752  3.053820\n",
       "97009   8.108846 -5.319327  -6.192122  ...  1.485384  0.710626 -2.989335\n",
       "223297  3.949012 -6.848152  -4.856686  ...  4.887293 -3.452863  9.012326\n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Questions 1 tfidf weighted word2vec\n",
    "df3_q1_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11439,
     "status": "ok",
     "timestamp": 1565716606333,
     "user": {
      "displayName": "Mukesh Mishra",
      "photoUrl": "https://lh4.googleusercontent.com/-sz7NIbVC0ho/AAAAAAAAAAI/AAAAAAAADcQ/UgdGcXvpJOI/s64/photo.jpg",
      "userId": "15923203954827925545"
     },
     "user_tz": -330
    },
    "id": "wUMdkJTNdMWL",
    "outputId": "672489d3-c6ac-48d8-b467-52d2169dc40d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157561</th>\n",
       "      <td>25.026054</td>\n",
       "      <td>-12.854203</td>\n",
       "      <td>-9.678908</td>\n",
       "      <td>-11.264161</td>\n",
       "      <td>-10.215891</td>\n",
       "      <td>-2.118202</td>\n",
       "      <td>31.566062</td>\n",
       "      <td>5.966860</td>\n",
       "      <td>-6.212604</td>\n",
       "      <td>12.947480</td>\n",
       "      <td>-4.721270</td>\n",
       "      <td>-6.075376</td>\n",
       "      <td>-8.535069</td>\n",
       "      <td>-16.209612</td>\n",
       "      <td>-1.013473</td>\n",
       "      <td>-2.965789</td>\n",
       "      <td>16.058956</td>\n",
       "      <td>11.943741</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>10.845661</td>\n",
       "      <td>-12.055827</td>\n",
       "      <td>-15.683305</td>\n",
       "      <td>9.624656</td>\n",
       "      <td>21.081420</td>\n",
       "      <td>-1.351233</td>\n",
       "      <td>-1.717200</td>\n",
       "      <td>11.987191</td>\n",
       "      <td>-12.667363</td>\n",
       "      <td>0.222950</td>\n",
       "      <td>34.281001</td>\n",
       "      <td>14.108251</td>\n",
       "      <td>4.945513</td>\n",
       "      <td>-4.849025</td>\n",
       "      <td>3.119186</td>\n",
       "      <td>13.476799</td>\n",
       "      <td>-1.176014</td>\n",
       "      <td>-17.232893</td>\n",
       "      <td>15.477876</td>\n",
       "      <td>1.626920</td>\n",
       "      <td>-2.543411</td>\n",
       "      <td>...</td>\n",
       "      <td>3.739769</td>\n",
       "      <td>-3.639188</td>\n",
       "      <td>-12.637721</td>\n",
       "      <td>2.332421</td>\n",
       "      <td>-12.133846</td>\n",
       "      <td>-2.304493</td>\n",
       "      <td>16.770844</td>\n",
       "      <td>-4.494542</td>\n",
       "      <td>-1.388609</td>\n",
       "      <td>16.372948</td>\n",
       "      <td>10.158867</td>\n",
       "      <td>5.490551</td>\n",
       "      <td>-7.762344</td>\n",
       "      <td>7.778493</td>\n",
       "      <td>-9.578330</td>\n",
       "      <td>-6.224568</td>\n",
       "      <td>-1.165697</td>\n",
       "      <td>20.776454</td>\n",
       "      <td>0.088872</td>\n",
       "      <td>17.565869</td>\n",
       "      <td>0.539370</td>\n",
       "      <td>-8.259760</td>\n",
       "      <td>-10.242416</td>\n",
       "      <td>-15.399972</td>\n",
       "      <td>-3.899840</td>\n",
       "      <td>-8.201684</td>\n",
       "      <td>-17.783960</td>\n",
       "      <td>12.739991</td>\n",
       "      <td>-5.722935</td>\n",
       "      <td>0.636866</td>\n",
       "      <td>6.719412</td>\n",
       "      <td>-0.219325</td>\n",
       "      <td>12.030707</td>\n",
       "      <td>1.111896</td>\n",
       "      <td>3.915992</td>\n",
       "      <td>-9.138846</td>\n",
       "      <td>3.601260</td>\n",
       "      <td>-1.824206</td>\n",
       "      <td>-4.753558</td>\n",
       "      <td>7.415056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55473</th>\n",
       "      <td>3.153236</td>\n",
       "      <td>-9.807701</td>\n",
       "      <td>-4.287981</td>\n",
       "      <td>-10.497754</td>\n",
       "      <td>-5.162055</td>\n",
       "      <td>-4.743260</td>\n",
       "      <td>8.219638</td>\n",
       "      <td>2.725274</td>\n",
       "      <td>0.194639</td>\n",
       "      <td>8.444565</td>\n",
       "      <td>-8.259800</td>\n",
       "      <td>8.336918</td>\n",
       "      <td>-18.307568</td>\n",
       "      <td>3.545547</td>\n",
       "      <td>3.067420</td>\n",
       "      <td>-6.419003</td>\n",
       "      <td>11.556953</td>\n",
       "      <td>5.623813</td>\n",
       "      <td>9.577541</td>\n",
       "      <td>8.728185</td>\n",
       "      <td>-4.954347</td>\n",
       "      <td>-11.130281</td>\n",
       "      <td>8.916562</td>\n",
       "      <td>22.158957</td>\n",
       "      <td>-2.558591</td>\n",
       "      <td>5.251475</td>\n",
       "      <td>9.028775</td>\n",
       "      <td>-4.468414</td>\n",
       "      <td>2.849426</td>\n",
       "      <td>13.956688</td>\n",
       "      <td>3.050223</td>\n",
       "      <td>-9.898802</td>\n",
       "      <td>-6.226555</td>\n",
       "      <td>-6.535197</td>\n",
       "      <td>9.464583</td>\n",
       "      <td>0.503888</td>\n",
       "      <td>-2.923849</td>\n",
       "      <td>9.747632</td>\n",
       "      <td>3.044790</td>\n",
       "      <td>8.853636</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.648263</td>\n",
       "      <td>-2.173418</td>\n",
       "      <td>-8.906834</td>\n",
       "      <td>0.579249</td>\n",
       "      <td>-8.044167</td>\n",
       "      <td>-6.576378</td>\n",
       "      <td>3.401646</td>\n",
       "      <td>1.723407</td>\n",
       "      <td>-9.300610</td>\n",
       "      <td>5.142695</td>\n",
       "      <td>6.977218</td>\n",
       "      <td>-1.098502</td>\n",
       "      <td>-7.410183</td>\n",
       "      <td>5.390485</td>\n",
       "      <td>4.047209</td>\n",
       "      <td>1.405818</td>\n",
       "      <td>6.973583</td>\n",
       "      <td>9.660406</td>\n",
       "      <td>8.529007</td>\n",
       "      <td>10.165295</td>\n",
       "      <td>3.022903</td>\n",
       "      <td>-8.904441</td>\n",
       "      <td>-3.226240</td>\n",
       "      <td>-5.012496</td>\n",
       "      <td>-1.124405</td>\n",
       "      <td>-2.878430</td>\n",
       "      <td>-7.709710</td>\n",
       "      <td>-2.355510</td>\n",
       "      <td>0.939109</td>\n",
       "      <td>-1.312647</td>\n",
       "      <td>7.843023</td>\n",
       "      <td>-4.867048</td>\n",
       "      <td>0.990400</td>\n",
       "      <td>6.969420</td>\n",
       "      <td>-0.948179</td>\n",
       "      <td>0.996781</td>\n",
       "      <td>-6.203502</td>\n",
       "      <td>1.911023</td>\n",
       "      <td>-2.651912</td>\n",
       "      <td>7.959680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58292</th>\n",
       "      <td>26.724261</td>\n",
       "      <td>-34.266608</td>\n",
       "      <td>-16.617415</td>\n",
       "      <td>-27.571456</td>\n",
       "      <td>-6.003354</td>\n",
       "      <td>5.019149</td>\n",
       "      <td>37.134820</td>\n",
       "      <td>13.056351</td>\n",
       "      <td>-15.587229</td>\n",
       "      <td>10.477277</td>\n",
       "      <td>2.765593</td>\n",
       "      <td>-14.594760</td>\n",
       "      <td>-7.860152</td>\n",
       "      <td>-24.994246</td>\n",
       "      <td>-18.802183</td>\n",
       "      <td>-12.016078</td>\n",
       "      <td>11.023600</td>\n",
       "      <td>29.320579</td>\n",
       "      <td>5.573961</td>\n",
       "      <td>28.354035</td>\n",
       "      <td>-19.603802</td>\n",
       "      <td>-14.745078</td>\n",
       "      <td>16.760176</td>\n",
       "      <td>31.883778</td>\n",
       "      <td>-15.563741</td>\n",
       "      <td>11.420548</td>\n",
       "      <td>1.538563</td>\n",
       "      <td>-20.740651</td>\n",
       "      <td>25.146940</td>\n",
       "      <td>40.070135</td>\n",
       "      <td>14.423905</td>\n",
       "      <td>-6.719687</td>\n",
       "      <td>-8.774575</td>\n",
       "      <td>-2.743660</td>\n",
       "      <td>26.832397</td>\n",
       "      <td>12.438938</td>\n",
       "      <td>-15.364844</td>\n",
       "      <td>9.559419</td>\n",
       "      <td>-1.773282</td>\n",
       "      <td>4.129486</td>\n",
       "      <td>...</td>\n",
       "      <td>8.978238</td>\n",
       "      <td>18.197583</td>\n",
       "      <td>-19.215146</td>\n",
       "      <td>-8.049232</td>\n",
       "      <td>-25.784281</td>\n",
       "      <td>22.559807</td>\n",
       "      <td>11.870551</td>\n",
       "      <td>4.348325</td>\n",
       "      <td>-11.609832</td>\n",
       "      <td>46.608410</td>\n",
       "      <td>0.164725</td>\n",
       "      <td>-15.373382</td>\n",
       "      <td>-2.142098</td>\n",
       "      <td>-8.943905</td>\n",
       "      <td>8.642553</td>\n",
       "      <td>14.615098</td>\n",
       "      <td>-13.177623</td>\n",
       "      <td>6.820156</td>\n",
       "      <td>-4.908731</td>\n",
       "      <td>2.981052</td>\n",
       "      <td>-4.649168</td>\n",
       "      <td>-16.732299</td>\n",
       "      <td>-3.984409</td>\n",
       "      <td>-29.297677</td>\n",
       "      <td>-23.371328</td>\n",
       "      <td>-14.268071</td>\n",
       "      <td>-18.879427</td>\n",
       "      <td>11.568874</td>\n",
       "      <td>8.576639</td>\n",
       "      <td>5.542166</td>\n",
       "      <td>21.837860</td>\n",
       "      <td>12.528985</td>\n",
       "      <td>7.359051</td>\n",
       "      <td>8.883575</td>\n",
       "      <td>10.581327</td>\n",
       "      <td>4.699246</td>\n",
       "      <td>-33.923656</td>\n",
       "      <td>1.174232</td>\n",
       "      <td>-17.885525</td>\n",
       "      <td>15.088691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124205</th>\n",
       "      <td>5.418724</td>\n",
       "      <td>-5.579635</td>\n",
       "      <td>-5.298835</td>\n",
       "      <td>-6.650882</td>\n",
       "      <td>-0.867129</td>\n",
       "      <td>2.277497</td>\n",
       "      <td>4.982583</td>\n",
       "      <td>14.247606</td>\n",
       "      <td>-7.309681</td>\n",
       "      <td>6.909354</td>\n",
       "      <td>-3.446842</td>\n",
       "      <td>-7.683994</td>\n",
       "      <td>-5.293639</td>\n",
       "      <td>-16.219441</td>\n",
       "      <td>-6.043888</td>\n",
       "      <td>1.211198</td>\n",
       "      <td>5.572096</td>\n",
       "      <td>6.957943</td>\n",
       "      <td>-5.052719</td>\n",
       "      <td>2.048629</td>\n",
       "      <td>-13.010932</td>\n",
       "      <td>-16.437561</td>\n",
       "      <td>16.343671</td>\n",
       "      <td>12.064842</td>\n",
       "      <td>-5.592797</td>\n",
       "      <td>-2.958274</td>\n",
       "      <td>1.391542</td>\n",
       "      <td>-2.258689</td>\n",
       "      <td>-1.658594</td>\n",
       "      <td>21.625799</td>\n",
       "      <td>2.594576</td>\n",
       "      <td>-0.417195</td>\n",
       "      <td>0.748362</td>\n",
       "      <td>5.162182</td>\n",
       "      <td>5.109074</td>\n",
       "      <td>3.174784</td>\n",
       "      <td>-4.425768</td>\n",
       "      <td>11.004832</td>\n",
       "      <td>10.252584</td>\n",
       "      <td>-7.471720</td>\n",
       "      <td>...</td>\n",
       "      <td>6.385204</td>\n",
       "      <td>0.045094</td>\n",
       "      <td>-14.788554</td>\n",
       "      <td>-1.442861</td>\n",
       "      <td>-7.546309</td>\n",
       "      <td>7.724198</td>\n",
       "      <td>5.200766</td>\n",
       "      <td>-1.504384</td>\n",
       "      <td>-5.170331</td>\n",
       "      <td>9.495537</td>\n",
       "      <td>6.647026</td>\n",
       "      <td>-1.193621</td>\n",
       "      <td>-5.480157</td>\n",
       "      <td>-3.688828</td>\n",
       "      <td>0.229512</td>\n",
       "      <td>2.551094</td>\n",
       "      <td>-7.200671</td>\n",
       "      <td>11.410437</td>\n",
       "      <td>-0.975199</td>\n",
       "      <td>9.962537</td>\n",
       "      <td>-4.054538</td>\n",
       "      <td>-4.443706</td>\n",
       "      <td>-0.263081</td>\n",
       "      <td>-5.218626</td>\n",
       "      <td>-3.661550</td>\n",
       "      <td>-4.962313</td>\n",
       "      <td>-15.658082</td>\n",
       "      <td>0.065376</td>\n",
       "      <td>3.870829</td>\n",
       "      <td>0.336733</td>\n",
       "      <td>8.675623</td>\n",
       "      <td>5.248007</td>\n",
       "      <td>7.049481</td>\n",
       "      <td>7.740102</td>\n",
       "      <td>12.570964</td>\n",
       "      <td>-1.202226</td>\n",
       "      <td>5.209290</td>\n",
       "      <td>3.629717</td>\n",
       "      <td>0.565035</td>\n",
       "      <td>2.699225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211135</th>\n",
       "      <td>-0.915871</td>\n",
       "      <td>-4.670748</td>\n",
       "      <td>-7.094173</td>\n",
       "      <td>-7.577088</td>\n",
       "      <td>-2.944890</td>\n",
       "      <td>4.100913</td>\n",
       "      <td>15.464195</td>\n",
       "      <td>8.516277</td>\n",
       "      <td>3.587404</td>\n",
       "      <td>1.071980</td>\n",
       "      <td>2.100014</td>\n",
       "      <td>5.814831</td>\n",
       "      <td>-8.225620</td>\n",
       "      <td>-2.280331</td>\n",
       "      <td>8.220332</td>\n",
       "      <td>-4.874116</td>\n",
       "      <td>5.708084</td>\n",
       "      <td>-0.164656</td>\n",
       "      <td>3.167801</td>\n",
       "      <td>7.425088</td>\n",
       "      <td>-10.760129</td>\n",
       "      <td>-7.883744</td>\n",
       "      <td>10.523446</td>\n",
       "      <td>14.110472</td>\n",
       "      <td>0.158759</td>\n",
       "      <td>5.130409</td>\n",
       "      <td>6.765922</td>\n",
       "      <td>-11.911552</td>\n",
       "      <td>5.810382</td>\n",
       "      <td>9.816580</td>\n",
       "      <td>7.550865</td>\n",
       "      <td>-0.436815</td>\n",
       "      <td>-0.959671</td>\n",
       "      <td>-1.466861</td>\n",
       "      <td>8.063568</td>\n",
       "      <td>4.092882</td>\n",
       "      <td>-0.198780</td>\n",
       "      <td>8.694429</td>\n",
       "      <td>-1.899203</td>\n",
       "      <td>6.387929</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.338168</td>\n",
       "      <td>-0.300005</td>\n",
       "      <td>-6.616566</td>\n",
       "      <td>-2.006314</td>\n",
       "      <td>-7.489709</td>\n",
       "      <td>-1.194568</td>\n",
       "      <td>0.150251</td>\n",
       "      <td>-7.649520</td>\n",
       "      <td>-3.309443</td>\n",
       "      <td>3.574505</td>\n",
       "      <td>4.160130</td>\n",
       "      <td>-3.219686</td>\n",
       "      <td>-8.375205</td>\n",
       "      <td>-0.047999</td>\n",
       "      <td>0.913080</td>\n",
       "      <td>-1.544992</td>\n",
       "      <td>9.609333</td>\n",
       "      <td>16.978956</td>\n",
       "      <td>7.009932</td>\n",
       "      <td>1.852150</td>\n",
       "      <td>0.695156</td>\n",
       "      <td>-9.495914</td>\n",
       "      <td>0.696076</td>\n",
       "      <td>-3.094993</td>\n",
       "      <td>-5.030147</td>\n",
       "      <td>-5.339262</td>\n",
       "      <td>-10.565187</td>\n",
       "      <td>9.628429</td>\n",
       "      <td>-6.163838</td>\n",
       "      <td>7.864265</td>\n",
       "      <td>8.310855</td>\n",
       "      <td>-6.031244</td>\n",
       "      <td>0.823020</td>\n",
       "      <td>-2.532165</td>\n",
       "      <td>3.211276</td>\n",
       "      <td>0.876316</td>\n",
       "      <td>-5.915461</td>\n",
       "      <td>3.359766</td>\n",
       "      <td>1.298573</td>\n",
       "      <td>4.637972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0          1          2   ...        93         94         95\n",
       "157561  25.026054 -12.854203  -9.678908  ... -1.824206  -4.753558   7.415056\n",
       "55473    3.153236  -9.807701  -4.287981  ...  1.911023  -2.651912   7.959680\n",
       "58292   26.724261 -34.266608 -16.617415  ...  1.174232 -17.885525  15.088691\n",
       "124205   5.418724  -5.579635  -5.298835  ...  3.629717   0.565035   2.699225\n",
       "211135  -0.915871  -4.670748  -7.094173  ...  3.359766   1.298573   4.637972\n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_q1_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ozz83vh4dMWU"
   },
   "outputs": [],
   "source": [
    "print(\"Number of features in nlp dataframe :\", df1.shape[1])\n",
    "print(\"Number of features in preprocessed dataframe :\", df2.shape[1])\n",
    "print(\"Number of features in question1 w2v  dataframe :\", df3_q1.shape[1])\n",
    "print(\"Number of features in question2 w2v  dataframe :\", df3_q2.shape[1])\n",
    "print(\"Number of features in final dataframe  :\", df1.shape[1]+df2.shape[1]+df3_q1.shape[1]+df3_q2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HmfZ5Q1zdMWl"
   },
   "outputs": [],
   "source": [
    "# storing the final features to csv file\n",
    "if not os.path.isfile('final_features.csv'):\n",
    "    df3_q1_train['id']=df_train['id']\n",
    "    df3_q2_train['id']=df_train['id']\n",
    "    \n",
    "    df3_q1_test['id']=df_test['id']\n",
    "    df3_q2_test['id']=df_test['id']\n",
    "    \n",
    "    df1  = df1.merge(df2, on='id',how='inner')\n",
    "    \n",
    "    df2_train  = df3_q1_train.merge(df3_q2_train, on='id',how='inner')\n",
    "    df2_test   = df3_q1_test.merge(df3_q2_test, on='id',how='inner')\n",
    "    \n",
    "    result_train  = df1.merge(df2_train, on='id',how='inner')\n",
    "    result_test  = df1.merge(df2_test, on='id',how='inner')\n",
    "    \n",
    "    \n",
    "    result_train.to_csv('final_features_train.csv')\n",
    "    result_test.to_csv('final_features_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 122152,
     "status": "ok",
     "timestamp": 1565716763322,
     "user": {
      "displayName": "Mukesh Mishra",
      "photoUrl": "https://lh4.googleusercontent.com/-sz7NIbVC0ho/AAAAAAAAAAI/AAAAAAAADcQ/UgdGcXvpJOI/s64/photo.jpg",
      "userId": "15923203954827925545"
     },
     "user_tz": -330
    },
    "id": "r875maGGuTLQ",
    "outputId": "e2af531c-43f7-4fc7-ec51-f5c25c321a7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80858, 220), (323432, 220))"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test.shape,result_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f0V1MzwOuL_N"
   },
   "source": [
    "<h3> XGBoost on TFIDF Weighted W2V on Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-08-13 19:14:42--  https://doc-00-58-docs.googleusercontent.com/docs/securesc/qgbh6kjdsd98f3gihp270udf3ooq8huc/72qp0q01ae1bdm21jllpmu1i3u8nh8fa/1565719200000/15923203954827925545/15923203954827925545/1NE36Qhqn27kUkhKpra_P2f3-tXsYl9xG?e=download\n",
      "Resolving doc-00-58-docs.googleusercontent.com (doc-00-58-docs.googleusercontent.com)... 74.125.197.132, 2607:f8b0:400e:c03::84\n",
      "Connecting to doc-00-58-docs.googleusercontent.com (doc-00-58-docs.googleusercontent.com)|74.125.197.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/csv]\n",
      "Saving to: ‘final_features_train.csv’\n",
      "\n",
      "final_features_trai     [     <=>            ]   1.16G   160MB/s    in 8.9s    \n",
      "\n",
      "2019-08-13 19:14:51 (133 MB/s) - ‘final_features_train.csv’ saved [1244544516]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --header=\"Host: doc-00-58-docs.googleusercontent.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" --header=\"Referer: https://drive.google.com/drive/u/0/search?q=final_features_train.csv\" --header=\"Cookie: AUTH_f79jrck61g36irfb06hiu34q4b401ieh=15923203954827925545|1565712000000|d97djekb9lmp9b90ntp4mn07qecbf4ub; _ga=GA1.2.1518331858.1560046699; NID=188=X_j5gZPQThhpMXzcQZW3ApzuX7j7tcWuSNfLk6HAhP4Z2qOb1ikhBgWppNK8wIFLZQN4AYCwVqeeJtlkQhtwpQbdRzP_iIDD5G_mnS4Ma2ZUCmGavezZ4Uj8s5I9uY7OxL0h0VLkireAEXtOJrXFFY5c-bFoqzaBbYligxKWvao\" --header=\"Connection: keep-alive\" \"https://doc-00-58-docs.googleusercontent.com/docs/securesc/qgbh6kjdsd98f3gihp270udf3ooq8huc/72qp0q01ae1bdm21jllpmu1i3u8nh8fa/1565719200000/15923203954827925545/15923203954827925545/1NE36Qhqn27kUkhKpra_P2f3-tXsYl9xG?e=download\" -O \"final_features_train.csv\" -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-08-13 19:15:20--  https://doc-08-58-docs.googleusercontent.com/docs/securesc/qgbh6kjdsd98f3gihp270udf3ooq8huc/3f4htdnq5pk7ck92fiukbahq2efnmbdj/1565719200000/15923203954827925545/15923203954827925545/11kPWHuyFUvomF-vwmkkIiKXryZNfXJIY?e=download\n",
      "Resolving doc-08-58-docs.googleusercontent.com (doc-08-58-docs.googleusercontent.com)... 74.125.197.132, 2607:f8b0:400e:c03::84\n",
      "Connecting to doc-08-58-docs.googleusercontent.com (doc-08-58-docs.googleusercontent.com)|74.125.197.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/csv]\n",
      "Saving to: ‘final_features_test.csv’\n",
      "\n",
      "final_features_test     [           <=>      ] 296.67M   103MB/s    in 2.9s    \n",
      "\n",
      "2019-08-13 19:15:23 (103 MB/s) - ‘final_features_test.csv’ saved [311078704]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --header=\"Host: doc-08-58-docs.googleusercontent.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" --header=\"Referer: https://drive.google.com/drive/u/0/search?q=final_features_test.csv\" --header=\"Cookie: AUTH_f79jrck61g36irfb06hiu34q4b401ieh=15923203954827925545|1565712000000|d97djekb9lmp9b90ntp4mn07qecbf4ub; _ga=GA1.2.1518331858.1560046699; NID=188=X_j5gZPQThhpMXzcQZW3ApzuX7j7tcWuSNfLk6HAhP4Z2qOb1ikhBgWppNK8wIFLZQN4AYCwVqeeJtlkQhtwpQbdRzP_iIDD5G_mnS4Ma2ZUCmGavezZ4Uj8s5I9uY7OxL0h0VLkireAEXtOJrXFFY5c-bFoqzaBbYligxKWvao\" --header=\"Connection: keep-alive\" \"https://doc-08-58-docs.googleusercontent.com/docs/securesc/qgbh6kjdsd98f3gihp270udf3ooq8huc/3f4htdnq5pk7ck92fiukbahq2efnmbdj/1565719200000/15923203954827925545/15923203954827925545/11kPWHuyFUvomF-vwmkkIiKXryZNfXJIY?e=download\" -O \"final_features_test.csv\" -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N5fFztqxuRL2"
   },
   "outputs": [],
   "source": [
    "result_train=pd.read_csv('final_features_train.csv')\n",
    "result_test=pd.read_csv('final_features_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "UVqr0ObTt36b",
    "outputId": "2f52a056-909f-42e6-ab9a-7a0f291b8439"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed: 104.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2, error_score='raise-deprecating',\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=100,\n",
       "                                           n_jobs=1, nthread=None,\n",
       "                                           objective='binary:logistic',\n",
       "                                           random_state=0, reg_alpha=0,\n",
       "                                           reg_lambda=1, scale_pos_weight=1,\n",
       "                                           seed=None, silent=None, subsample=1,\n",
       "                                           verbosity=1),\n",
       "                   iid='warn', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.1, 0.5, 1],\n",
       "                                        'learning_rate': [0.01, 0.1, 0.2],\n",
       "                                        'max_depth': [3, 5, 8],\n",
       "                                        'n_estimators': [100, 500, 1000],\n",
       "                                        'subsample': [0.1, 0.5, 1]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='neg_log_loss', verbose=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "y_train=result_train['is_duplicate']\n",
    "y_test=result_test['is_duplicate']\n",
    "X_tr=result_train.drop(['is_duplicate'],axis=1)\n",
    "X_te=result_test.drop(['is_duplicate'],axis=1)\n",
    "\n",
    "\n",
    "x_cfl=xgb.XGBClassifier()\n",
    "\n",
    "prams = {\n",
    "    'learning_rate':[0.01,0.1,0.2],\n",
    "     'n_estimators':[100,500,1000],\n",
    "     'max_depth':[3,5,8],\n",
    "    'colsample_bytree':[0.1,0.5,1],\n",
    "    'subsample':[0.1,0.5,1]\n",
    "}\n",
    "random_cfl1=RandomizedSearchCV(x_cfl,param_distributions=prams,scoring='neg_log_loss',cv=2,verbose=1,n_jobs=-1)\n",
    "random_cfl1.fit(X_tr,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eAACo2fV_6Fx"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "source = os.listdir(\"/content\")\n",
    "destination = \"/content/drive/My Drive\"\n",
    "for files in source:\n",
    "    if files.endswith(\".csv\"):\n",
    "        shutil.copy(files,destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A8P484mZuytO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.1, 'n_estimators': 500, 'colsample_bytree': 0.1, 'max_depth': 5, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "print (random_cfl1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hLEqTLfZu9ij"
   },
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "cfl=xgb.XGBClassifier(n_estimators=500,subsample=0.1,learning_rate=0.01,colsample_bytree=0.1,max_depth=5)\n",
    "cfl.fit(X_tr,y_train)\n",
    "c_cfl=CalibratedClassifierCV(x_cfl,method='sigmoid')\n",
    "c_cfl.fit(X_tr,y_train)\n",
    "\n",
    "predict_y = c_cfl.predict_proba(X_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jGkLjKazvESG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.39909822481038637\n",
      "test loss 0.40790524897003333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print ('train loss',log_loss(y_train, predict_y))\n",
    "predict_y = c_cfl.predict_proba(X_te)\n",
    "print ('test loss',log_loss(y_test, predict_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gDif27z7vHaF"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#y_test = list(map(int, y_test.values))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "predicted_y =np.array(predict_y>0.5,dtype=int)\n",
    "plot_confusion_matrix(y_test, predicted_y[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ipJ4l19mvPaG"
   },
   "outputs": [],
   "source": [
    "# This function plots the confusion matrices given y_i, y_i_hat.\n",
    "from sklearn.metrics import log_loss\n",
    "def plot_confusion_matrix(test_y, predict_y):\n",
    "    C = confusion_matrix(test_y, predict_y)\n",
    "    # C = 9,9 matrix, each cell (i,j) represents number of points of class i are predicted class j\n",
    "    \n",
    "    A =(((C.T)/(C.sum(axis=1))).T)\n",
    "    #divid each element of the confusion matrix with the sum of elements in that column\n",
    "    \n",
    "    # C = [[1, 2],\n",
    "    #     [3, 4]]\n",
    "    # C.T = [[1, 3],\n",
    "    #        [2, 4]]\n",
    "    # C.sum(axis = 1)  axis=0 corresonds to columns and axis=1 corresponds to rows in two diamensional array\n",
    "    # C.sum(axix =1) = [[3, 7]]\n",
    "    # ((C.T)/(C.sum(axis=1))) = [[1/3, 3/7]\n",
    "    #                           [2/3, 4/7]]\n",
    "\n",
    "    # ((C.T)/(C.sum(axis=1))).T = [[1/3, 2/3]\n",
    "    #                           [3/7, 4/7]]\n",
    "    # sum of row elements = 1\n",
    "    \n",
    "    B =(C/C.sum(axis=0))\n",
    "    #divid each element of the confusion matrix with the sum of elements in that row\n",
    "    # C = [[1, 2],\n",
    "    #     [3, 4]]\n",
    "    # C.sum(axis = 0)  axis=0 corresonds to columns and axis=1 corresponds to rows in two diamensional array\n",
    "    # C.sum(axix =0) = [[4, 6]]\n",
    "    # (C/C.sum(axis=0)) = [[1/4, 2/6],\n",
    "    #                      [3/4, 4/6]] \n",
    "    plt.figure(figsize=(20,4))\n",
    "    \n",
    "    labels = [1,2]\n",
    "    # representing A in heatmap format\n",
    "    cmap=sns.light_palette(\"blue\")\n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.heatmap(C, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    sns.heatmap(B, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Precision matrix\")\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    # representing B in heatmap format\n",
    "    sns.heatmap(A, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Recall matrix\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the Train Logloss is 0.39909822481038637 <br>\n",
    "and the Test Logloss 0.40790524897003333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "3_Q_Mean_W2V.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
